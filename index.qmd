---
talk-title: " MESSI-benchmark"
talk-subtitle: "MESSI: Multiomics Experiments with SyStematic Interrogation"
talk-descrip: "A pipeline for benchmarking multi-omics integration methods on classification problems using Nextflow"
author: "Chunqing Tony Liang"
other-authors: "Dr. Amrit Singh"
talk-date: "March 15, 2024"
format: revealjs
---



## {#title background-image="assets/website_bkg.png" background-position="top"}

<!--- setup r lib -->
```{r}
#| label: "setup"
#| echo: false
#| include: false
#| eval: true

library(knitr)
library(cowplot)
```



<br>
<br>
<br>
<br>
<br>
<br>


### {{< meta talk-subtitle >}} 

::: {.f2}

{{< meta talk-descrip >}}

:::

<br>

<br>


::: {.f3 .bold}

{{< meta author >}} 

PhD student in Bioinformatics

Supervisor: {{< meta other-authors >}}

{{< meta talk-date >}}

:::

<!-- {{< include _titleslide.qmd >}} -->


## Multiomics data and analysis

:::: {.columns}

::: {.column width="48%"}

```{r}
#| label: "fig-multiomics-intro"
#| fig-align: center
#| fig-cap-location: margin
#| fig-cap: "               Overview of multiomics data and integration ^[@shannon2024commentary]"
knitr::include_graphics("assets/multi-omics-integration.png")
```

:::

::: {.column width="52%"}

<br>

<br>

::: {.callout-tip}

# Motivation

- Technological advancement and reduced costs --> studies with multiomics data

- Multiomics data --> /single-cell/spatial data

- More generalized --> "multimodal data", other non-omics data

- Types of integrations: by sample (N), by omics (P), or both

:::

:::

::::


## Multiomics data integration methods

:::: {.columns}

::: {.column width="45%"}

```{r out.width="600px", out.height="480px"}
#| label: "fig-integration-methods"
#| fig-align: center
#| fig-cap-location: bottom
#| fig-cap: "Overview of multi-omics data integration tools ^[@subramanian2020multi]"
knitr::include_graphics("assets/methods_avail.jpg")
```

:::
<!--- Empty column here --->
::: {.column width="5%"} 
<!--- Empty column here --->
:::


::: {.column width="50%"}

<br>

::: {.callout-note .fragment}

# Question arises

- Many integration methods 
  
  ---> Which to use, how to choose them?

- Reproducibility crisis 
  
  ---> How to reproduce method and get reliable results?

- Existing benchmark studies are not 100% complete or all-encompassing

  ---> Technical difficulty in implementation?

:::

:::

::::


## The MESSI workflow

:::: {.columns}

::: {.column width="50%"}

```{r}
#| label: "fig-messi-overview-new"
#| fig-align: center
#| fig-cap: "Overview of MESSI workflow"
knitr::include_graphics("assets/messi_workflow.png")
```

:::

::: {.column width="6%"}
:::

::: {.column width="44%"}

- This is done in **Nextflow** [@di2017nextflow], and will be publicly available in **nf-core** [@ewels2020nf].

- Generalizable for more integration methods, more tasks

- Solves reproducibility issue through independent method containers

- Compare large set of data at once

:::

::::


## Methods

- Looking into multiview [@ding2022cooperative], DIABLO [@singh2019diablo], RGCCA [@girka2023multiblock], MOFA [@argelaguet2018multi], MOGONET (python) [@wang2021mogonet] 
- Validating with known ground truth data from **500+** simulated multiomics data with varying parameters
  - Number of subjects/patients
  - Number of predictors/features/biomarkers
  - [Correlation]{.tertiary} between omics
  - "Signal" to distinguish groups (binary response) 
- Evaluating on **6** real world data
- Using a **5-fold** cross validation with [AUC]{.secondary} score as metric

::: {.notes}

- R-based one are usually not deep learning based, this is of bad GPU support and focus more on statistics

:::


## Signal and correlation are sensitive parameters to integration methods

:::: {.columns}

::: {.column width="50%"}

```{r}
#| label: "fig-perf-sim"
#| fig-align: center
#| fig-cap: "5-fold CV AUC score on simulated data with varying correlation and signal"
knitr::include_graphics("assets/computed_results/fig_performance_evaluation_sim.png")
```

:::

::: {.column width="2%"}

:::

::: {.column width="48%"} 

- **Higher signal**, better performance, easier for methods to predict the response

- **Higher correlation**, possibly lower performance, additional test required

- [placeholder]{.primary} is the best, with marginal difference with ...

- [MOGONET]{.secondary} is the worst despite it is deep learning based

- Methods perform quite well when given little signal with AUC score ~ **0.7**

:::

::::

## High variability when identifying the important predictors

:::: {.columns}

::: {.column width="50%"}

```{r}
#| label: "fig-feat-sim"
#| fig-align: center
#| fig-cap: "Feat identification"
knitr::include_graphics("assets/computed_results/fig_feature_selection_sim.png")
```

:::

::: {.column width="2%"}
:::

::: {.column width="48%"}

- [Multiview]{.primary} have consistenly identifying important predictors even when **low** signal or correlation
- Rest methods seemed to have variety of sensitivity with different parameter settings, unstable
- [Mogonet]{.secondary} performs worst, have constantly low median of sensitivity capped ~ 0.1

- Placeholder

:::

::::


## No universal method that work well on all datasets

:::: {.columns}

::: {.column width="46%"}

```{r}
#| label: "fig-perf-real"
#| fig-align: center
#| fig-cap: "5-fold CV AUC score on real data"
knitr::include_graphics("assets/computed_results/fig_performance_evaluation_real.png")
```

:::

::: {.column width="2%"}
:::

::: {.column width="52%"}

- All methods are unique by their own, and specialized on certain property, no method work well on all data
- Some methods are similar to each other, i.e. solving similar optimization problem, model setup
- Similarly, data could have alike distributions
- There are data that have very **complex** pattern, make method hard to predict

:::

::::

## Ranking of important biomarkers varies by method


:::: {.columns}

::: {.column width="44%"}

```{r}
#| label: "fig-feat-real"
#| fig-align: center
#| fig-cap: "Feat identification on real data"
knitr::include_graphics("assets/computed_results/fig_feature_selection_real.png")
```

:::

::: {.column width="2%"}
:::

::: {.column width="54%"}

- Methods do not use same metric to quantify whether certain biomarker is important, so ranks on these are different
- Rare case where methods coincide with their ranking, possible from similar model setup
- Similar data cluster with each, i.e. GSE71669 with tcga-blca, both look into bladder cancer
- Placeholder

:::

::::

## Computational time is more sensible to number of predictors rather than subjects

<!-- ```{r}
#| label: fig-comp-time
#| fig-cap: "Compuational Time"
#| fig-subcap: 
#|   - "Simulated"
#|   - "Real"
#| layout-ncol: 2


knitr::include_graphics("assets/computed_results/fig_computational_time_sim.png")
knitr::include_graphics("assets/computed_results/fig_computational_time_real.png")
``` -->

```{r}
#| label: fig-comp-time
#| fig-cap: "Computational time from preprocessing to evaluation"
knitr::include_graphics("assets/computed_results/new_comp_time.png")

```

## Discussion & Future directions {.smaller}

- "No method works universally well on all datasets"
- Classic statistical methods still work, and even better than DL
- Pipeline proves way to reproducibliy explore, benchmark different aspects of integration methods
  - Resumable
  - Parallel to compute as many as resources allow at the same time
  - Ease burden of [setting up environment]{.secondary}

- Need to add more methods and datasets
  - Specially DL models are more popular now
  - Explore if any dataset could have relation to another despite different disease/condition

::: {.callout-note}

This is ongoing work!

:::


# Thanks! {.thanks}

## {#acknowledgements .smaller}



### Acknowledgements

:::: {.columns}

::: {.column width="50%"}


- [Dr. Amrit Singh]{.bold}
- Dr. Young Woong Kim
- Dr. Maryam Ahmadzadeh
- Rishika Daswani
- Roy He
- Michael Yoon
- Jeffrey Tang
- Akshdeep Sandhu
- Yovindu Don
- Raam Sivakumar
- Prabhleen Sandhu
- Mingming Zhang
- Samuel Leung

:::
::: {.column width="50%"}

```{r}
knitr::include_graphics("assets/lab_pic.jpg")
```

:::

::::


::: {.footer}
![](assets/logo.png)
:::

## References

::: {#refs}
:::
